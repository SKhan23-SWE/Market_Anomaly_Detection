{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1111, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Data</th>\n",
       "      <th>XAU BGNL</th>\n",
       "      <th>ECSURPUS</th>\n",
       "      <th>BDIY</th>\n",
       "      <th>CRY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>Cl1</th>\n",
       "      <th>...</th>\n",
       "      <th>LP01TREU</th>\n",
       "      <th>EMUSTRUU</th>\n",
       "      <th>LF94TRUU</th>\n",
       "      <th>MXUS</th>\n",
       "      <th>MXEU</th>\n",
       "      <th>MXJP</th>\n",
       "      <th>MXBR</th>\n",
       "      <th>MXRU</th>\n",
       "      <th>MXIN</th>\n",
       "      <th>MXCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1/11/2000</td>\n",
       "      <td>283.25</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>157.26</td>\n",
       "      <td>100.56</td>\n",
       "      <td>105.86</td>\n",
       "      <td>1.646</td>\n",
       "      <td>25.77</td>\n",
       "      <td>...</td>\n",
       "      <td>116.464</td>\n",
       "      <td>230.527</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1416.12</td>\n",
       "      <td>127.75</td>\n",
       "      <td>990.59</td>\n",
       "      <td>856.76</td>\n",
       "      <td>224.33</td>\n",
       "      <td>217.34</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1/18/2000</td>\n",
       "      <td>287.65</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>165.01</td>\n",
       "      <td>101.86</td>\n",
       "      <td>105.47</td>\n",
       "      <td>1.638</td>\n",
       "      <td>28.85</td>\n",
       "      <td>...</td>\n",
       "      <td>117.267</td>\n",
       "      <td>231.377</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1428.79</td>\n",
       "      <td>129.50</td>\n",
       "      <td>993.98</td>\n",
       "      <td>925.22</td>\n",
       "      <td>234.37</td>\n",
       "      <td>227.08</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1/25/2000</td>\n",
       "      <td>287.15</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>167.24</td>\n",
       "      <td>102.41</td>\n",
       "      <td>106.04</td>\n",
       "      <td>1.650</td>\n",
       "      <td>28.28</td>\n",
       "      <td>...</td>\n",
       "      <td>117.995</td>\n",
       "      <td>232.390</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1385.93</td>\n",
       "      <td>126.48</td>\n",
       "      <td>974.83</td>\n",
       "      <td>886.93</td>\n",
       "      <td>216.82</td>\n",
       "      <td>233.00</td>\n",
       "      <td>32.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2/1/2000</td>\n",
       "      <td>282.75</td>\n",
       "      <td>0.191</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>166.85</td>\n",
       "      <td>104.92</td>\n",
       "      <td>107.85</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.22</td>\n",
       "      <td>...</td>\n",
       "      <td>120.510</td>\n",
       "      <td>231.942</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1385.31</td>\n",
       "      <td>129.19</td>\n",
       "      <td>1007.12</td>\n",
       "      <td>842.60</td>\n",
       "      <td>201.89</td>\n",
       "      <td>237.48</td>\n",
       "      <td>31.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2/8/2000</td>\n",
       "      <td>298.40</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>165.43</td>\n",
       "      <td>104.22</td>\n",
       "      <td>109.30</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.02</td>\n",
       "      <td>...</td>\n",
       "      <td>118.791</td>\n",
       "      <td>237.812</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1411.95</td>\n",
       "      <td>134.67</td>\n",
       "      <td>1034.58</td>\n",
       "      <td>945.15</td>\n",
       "      <td>218.00</td>\n",
       "      <td>258.02</td>\n",
       "      <td>31.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y       Data  XAU BGNL  ECSURPUS    BDIY     CRY     DXY     JPY    GBP  \\\n",
       "0  0  1/11/2000    283.25     0.077  1388.0  157.26  100.56  105.86  1.646   \n",
       "1  0  1/18/2000    287.65     0.043  1405.0  165.01  101.86  105.47  1.638   \n",
       "2  0  1/25/2000    287.15     0.135  1368.0  167.24  102.41  106.04  1.650   \n",
       "3  0   2/1/2000    282.75     0.191  1311.0  166.85  104.92  107.85  1.611   \n",
       "4  1   2/8/2000    298.40     0.312  1277.0  165.43  104.22  109.30  1.611   \n",
       "\n",
       "     Cl1  ...  LP01TREU  EMUSTRUU  LF94TRUU     MXUS    MXEU     MXJP    MXBR  \\\n",
       "0  25.77  ...   116.464   230.527   123.762  1416.12  127.75   990.59  856.76   \n",
       "1  28.85  ...   117.267   231.377   123.762  1428.79  129.50   993.98  925.22   \n",
       "2  28.28  ...   117.995   232.390   123.762  1385.93  126.48   974.83  886.93   \n",
       "3  28.22  ...   120.510   231.942   122.328  1385.31  129.19  1007.12  842.60   \n",
       "4  28.02  ...   118.791   237.812   122.328  1411.95  134.67  1034.58  945.15   \n",
       "\n",
       "     MXRU    MXIN   MXCN  \n",
       "0  224.33  217.34  34.30  \n",
       "1  234.37  227.08  32.74  \n",
       "2  216.82  233.00  32.46  \n",
       "3  201.89  237.48  31.29  \n",
       "4  218.00  258.02  31.32  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FinancialMarketData.xlsx - EWS.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y            0\n",
      "Data         0\n",
      "XAU BGNL     0\n",
      "ECSURPUS     0\n",
      "BDIY         0\n",
      "CRY          0\n",
      "DXY          0\n",
      "JPY          0\n",
      "GBP          0\n",
      "Cl1          0\n",
      "VIX          0\n",
      "USGG30YR     0\n",
      "GT10         0\n",
      "USGG2YR      0\n",
      "USGG3M       0\n",
      "US0001M      0\n",
      "GTDEM30Y     0\n",
      "GTDEM10Y     0\n",
      "GTDEM2Y      0\n",
      "EONIA        0\n",
      "GTITL30YR    0\n",
      "GTITL10YR    0\n",
      "GTITL2YR     0\n",
      "GTJPY30YR    0\n",
      "GTJPY10YR    0\n",
      "GTJPY2YR     0\n",
      "GTGBP30Y     0\n",
      "GTGBP20Y     0\n",
      "GTGBP2Y      0\n",
      "LUMSTRUU     0\n",
      "LMBITR       0\n",
      "LUACTRUU     0\n",
      "LF98TRUU     0\n",
      "LG30TRUU     0\n",
      "LP01TREU     0\n",
      "EMUSTRUU     0\n",
      "LF94TRUU     0\n",
      "MXUS         0\n",
      "MXEU         0\n",
      "MXJP         0\n",
      "MXBR         0\n",
      "MXRU         0\n",
      "MXIN         0\n",
      "MXCN         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [874 237]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "(unique, counts) = np.unique(df['Y'], return_counts=True)\n",
    "print(unique, counts)\n",
    "sns.barplot(x=unique, y=counts)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks()\n",
    "plt.title('Target variable counts in dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XAU BGNL</th>\n",
       "      <th>ECSURPUS</th>\n",
       "      <th>BDIY</th>\n",
       "      <th>CRY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>Cl1</th>\n",
       "      <th>VIX</th>\n",
       "      <th>USGG30YR</th>\n",
       "      <th>...</th>\n",
       "      <th>LP01TREU</th>\n",
       "      <th>EMUSTRUU</th>\n",
       "      <th>LF94TRUU</th>\n",
       "      <th>MXUS</th>\n",
       "      <th>MXEU</th>\n",
       "      <th>MXJP</th>\n",
       "      <th>MXBR</th>\n",
       "      <th>MXRU</th>\n",
       "      <th>MXIN</th>\n",
       "      <th>MXCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.25</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>157.26</td>\n",
       "      <td>100.56</td>\n",
       "      <td>105.86</td>\n",
       "      <td>1.646</td>\n",
       "      <td>25.77</td>\n",
       "      <td>22.50</td>\n",
       "      <td>6.671</td>\n",
       "      <td>...</td>\n",
       "      <td>116.464</td>\n",
       "      <td>230.527</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1416.12</td>\n",
       "      <td>127.75</td>\n",
       "      <td>990.59</td>\n",
       "      <td>856.76</td>\n",
       "      <td>224.33</td>\n",
       "      <td>217.34</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287.65</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>165.01</td>\n",
       "      <td>101.86</td>\n",
       "      <td>105.47</td>\n",
       "      <td>1.638</td>\n",
       "      <td>28.85</td>\n",
       "      <td>21.50</td>\n",
       "      <td>6.747</td>\n",
       "      <td>...</td>\n",
       "      <td>117.267</td>\n",
       "      <td>231.377</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1428.79</td>\n",
       "      <td>129.50</td>\n",
       "      <td>993.98</td>\n",
       "      <td>925.22</td>\n",
       "      <td>234.37</td>\n",
       "      <td>227.08</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287.15</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>167.24</td>\n",
       "      <td>102.41</td>\n",
       "      <td>106.04</td>\n",
       "      <td>1.650</td>\n",
       "      <td>28.28</td>\n",
       "      <td>23.02</td>\n",
       "      <td>6.634</td>\n",
       "      <td>...</td>\n",
       "      <td>117.995</td>\n",
       "      <td>232.390</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1385.93</td>\n",
       "      <td>126.48</td>\n",
       "      <td>974.83</td>\n",
       "      <td>886.93</td>\n",
       "      <td>216.82</td>\n",
       "      <td>233.00</td>\n",
       "      <td>32.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.75</td>\n",
       "      <td>0.191</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>166.85</td>\n",
       "      <td>104.92</td>\n",
       "      <td>107.85</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.22</td>\n",
       "      <td>23.45</td>\n",
       "      <td>6.423</td>\n",
       "      <td>...</td>\n",
       "      <td>120.510</td>\n",
       "      <td>231.942</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1385.31</td>\n",
       "      <td>129.19</td>\n",
       "      <td>1007.12</td>\n",
       "      <td>842.60</td>\n",
       "      <td>201.89</td>\n",
       "      <td>237.48</td>\n",
       "      <td>31.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.40</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>165.43</td>\n",
       "      <td>104.22</td>\n",
       "      <td>109.30</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.02</td>\n",
       "      <td>21.25</td>\n",
       "      <td>6.231</td>\n",
       "      <td>...</td>\n",
       "      <td>118.791</td>\n",
       "      <td>237.812</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1411.95</td>\n",
       "      <td>134.67</td>\n",
       "      <td>1034.58</td>\n",
       "      <td>945.15</td>\n",
       "      <td>218.00</td>\n",
       "      <td>258.02</td>\n",
       "      <td>31.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   XAU BGNL  ECSURPUS    BDIY     CRY     DXY     JPY    GBP    Cl1    VIX  \\\n",
       "0    283.25     0.077  1388.0  157.26  100.56  105.86  1.646  25.77  22.50   \n",
       "1    287.65     0.043  1405.0  165.01  101.86  105.47  1.638  28.85  21.50   \n",
       "2    287.15     0.135  1368.0  167.24  102.41  106.04  1.650  28.28  23.02   \n",
       "3    282.75     0.191  1311.0  166.85  104.92  107.85  1.611  28.22  23.45   \n",
       "4    298.40     0.312  1277.0  165.43  104.22  109.30  1.611  28.02  21.25   \n",
       "\n",
       "   USGG30YR  ...  LP01TREU  EMUSTRUU  LF94TRUU     MXUS    MXEU     MXJP  \\\n",
       "0     6.671  ...   116.464   230.527   123.762  1416.12  127.75   990.59   \n",
       "1     6.747  ...   117.267   231.377   123.762  1428.79  129.50   993.98   \n",
       "2     6.634  ...   117.995   232.390   123.762  1385.93  126.48   974.83   \n",
       "3     6.423  ...   120.510   231.942   122.328  1385.31  129.19  1007.12   \n",
       "4     6.231  ...   118.791   237.812   122.328  1411.95  134.67  1034.58   \n",
       "\n",
       "     MXBR    MXRU    MXIN   MXCN  \n",
       "0  856.76  224.33  217.34  34.30  \n",
       "1  925.22  234.37  227.08  32.74  \n",
       "2  886.93  216.82  233.00  32.46  \n",
       "3  842.60  201.89  237.48  31.29  \n",
       "4  945.15  218.00  258.02  31.32  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_status = df['Y']\n",
    "# features = df.loc[:, ['ECSURPUS', 'JPY', 'GBP', 'Cl1', 'VIX', 'EONIA']]\n",
    "features = df.drop(['Y', 'Data'], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XAU BGNL</th>\n",
       "      <th>ECSURPUS</th>\n",
       "      <th>BDIY</th>\n",
       "      <th>CRY</th>\n",
       "      <th>DXY</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>Cl1</th>\n",
       "      <th>VIX</th>\n",
       "      <th>USGG30YR</th>\n",
       "      <th>...</th>\n",
       "      <th>LP01TREU</th>\n",
       "      <th>EMUSTRUU</th>\n",
       "      <th>LF94TRUU</th>\n",
       "      <th>MXUS</th>\n",
       "      <th>MXEU</th>\n",
       "      <th>MXJP</th>\n",
       "      <th>MXBR</th>\n",
       "      <th>MXRU</th>\n",
       "      <th>MXIN</th>\n",
       "      <th>MXCN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.25</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>157.26</td>\n",
       "      <td>100.56</td>\n",
       "      <td>105.86</td>\n",
       "      <td>1.646</td>\n",
       "      <td>25.77</td>\n",
       "      <td>22.50</td>\n",
       "      <td>6.671</td>\n",
       "      <td>...</td>\n",
       "      <td>116.464</td>\n",
       "      <td>230.527</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1416.12</td>\n",
       "      <td>127.75</td>\n",
       "      <td>990.59</td>\n",
       "      <td>856.76</td>\n",
       "      <td>224.33</td>\n",
       "      <td>217.34</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287.65</td>\n",
       "      <td>0.043</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>165.01</td>\n",
       "      <td>101.86</td>\n",
       "      <td>105.47</td>\n",
       "      <td>1.638</td>\n",
       "      <td>28.85</td>\n",
       "      <td>21.50</td>\n",
       "      <td>6.747</td>\n",
       "      <td>...</td>\n",
       "      <td>117.267</td>\n",
       "      <td>231.377</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1428.79</td>\n",
       "      <td>129.50</td>\n",
       "      <td>993.98</td>\n",
       "      <td>925.22</td>\n",
       "      <td>234.37</td>\n",
       "      <td>227.08</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287.15</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>167.24</td>\n",
       "      <td>102.41</td>\n",
       "      <td>106.04</td>\n",
       "      <td>1.650</td>\n",
       "      <td>28.28</td>\n",
       "      <td>23.02</td>\n",
       "      <td>6.634</td>\n",
       "      <td>...</td>\n",
       "      <td>117.995</td>\n",
       "      <td>232.390</td>\n",
       "      <td>123.762</td>\n",
       "      <td>1385.93</td>\n",
       "      <td>126.48</td>\n",
       "      <td>974.83</td>\n",
       "      <td>886.93</td>\n",
       "      <td>216.82</td>\n",
       "      <td>233.00</td>\n",
       "      <td>32.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282.75</td>\n",
       "      <td>0.191</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>166.85</td>\n",
       "      <td>104.92</td>\n",
       "      <td>107.85</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.22</td>\n",
       "      <td>23.45</td>\n",
       "      <td>6.423</td>\n",
       "      <td>...</td>\n",
       "      <td>120.510</td>\n",
       "      <td>231.942</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1385.31</td>\n",
       "      <td>129.19</td>\n",
       "      <td>1007.12</td>\n",
       "      <td>842.60</td>\n",
       "      <td>201.89</td>\n",
       "      <td>237.48</td>\n",
       "      <td>31.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.40</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>165.43</td>\n",
       "      <td>104.22</td>\n",
       "      <td>109.30</td>\n",
       "      <td>1.611</td>\n",
       "      <td>28.02</td>\n",
       "      <td>21.25</td>\n",
       "      <td>6.231</td>\n",
       "      <td>...</td>\n",
       "      <td>118.791</td>\n",
       "      <td>237.812</td>\n",
       "      <td>122.328</td>\n",
       "      <td>1411.95</td>\n",
       "      <td>134.67</td>\n",
       "      <td>1034.58</td>\n",
       "      <td>945.15</td>\n",
       "      <td>218.00</td>\n",
       "      <td>258.02</td>\n",
       "      <td>31.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   XAU BGNL  ECSURPUS    BDIY     CRY     DXY     JPY    GBP    Cl1    VIX  \\\n",
       "0    283.25     0.077  1388.0  157.26  100.56  105.86  1.646  25.77  22.50   \n",
       "1    287.65     0.043  1405.0  165.01  101.86  105.47  1.638  28.85  21.50   \n",
       "2    287.15     0.135  1368.0  167.24  102.41  106.04  1.650  28.28  23.02   \n",
       "3    282.75     0.191  1311.0  166.85  104.92  107.85  1.611  28.22  23.45   \n",
       "4    298.40     0.312  1277.0  165.43  104.22  109.30  1.611  28.02  21.25   \n",
       "\n",
       "   USGG30YR  ...  LP01TREU  EMUSTRUU  LF94TRUU     MXUS    MXEU     MXJP  \\\n",
       "0     6.671  ...   116.464   230.527   123.762  1416.12  127.75   990.59   \n",
       "1     6.747  ...   117.267   231.377   123.762  1428.79  129.50   993.98   \n",
       "2     6.634  ...   117.995   232.390   123.762  1385.93  126.48   974.83   \n",
       "3     6.423  ...   120.510   231.942   122.328  1385.31  129.19  1007.12   \n",
       "4     6.231  ...   118.791   237.812   122.328  1411.95  134.67  1034.58   \n",
       "\n",
       "     MXBR    MXRU    MXIN   MXCN  \n",
       "0  856.76  224.33  217.34  34.30  \n",
       "1  925.22  234.37  227.08  32.74  \n",
       "2  886.93  216.82  233.00  32.46  \n",
       "3  842.60  201.89  237.48  31.29  \n",
       "4  945.15  218.00  258.02  31.32  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(features, crash_status, test_size=0.3, shuffle=False)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\khans\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:  LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       295\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.88       334\n",
      "   macro avg       0.44      0.50      0.47       334\n",
      "weighted avg       0.78      0.88      0.83       334\n",
      "\n",
      "ROC_AUC_SCORE is 0.5\n",
      "Classification Report:  Decision Trees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       295\n",
      "           1       0.94      0.41      0.57        39\n",
      "\n",
      "    accuracy                           0.93       334\n",
      "   macro avg       0.93      0.70      0.77       334\n",
      "weighted avg       0.93      0.93      0.92       334\n",
      "\n",
      "ROC_AUC_SCORE is 0.7034332898739678\n",
      "Classification Report:  Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       295\n",
      "           1       0.31      0.56      0.40        39\n",
      "\n",
      "    accuracy                           0.80       334\n",
      "   macro avg       0.62      0.70      0.64       334\n",
      "weighted avg       0.86      0.80      0.83       334\n",
      "\n",
      "ROC_AUC_SCORE is 0.6990004345936549\n",
      "Classification Report:  Xgboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       295\n",
      "           1       0.50      0.51      0.51        39\n",
      "\n",
      "    accuracy                           0.88       334\n",
      "   macro avg       0.72      0.72      0.72       334\n",
      "weighted avg       0.88      0.88      0.88       334\n",
      "\n",
      "ROC_AUC_SCORE is 0.7225119513255106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "models['LogisticRegression'] = LogisticRegression(max_iter=100)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Isolation Forest\n",
    "# models['Isolation Forest'] = IsolationForest()\n",
    "\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# XGBoost\n",
    "models['Xgboost'] = XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "accuracy, precision, recall, f1score, support = {}, {}, {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "\n",
    "    #Fit the classifier model\n",
    "    models[key].fit(X_train, Y_train)\n",
    "\n",
    "    #Prediction\n",
    "    predictions = models[key].predict(X_val)\n",
    "\n",
    "    # Calculate \n",
    "    accuracy[key] = accuracy_score(predictions, Y_val)\n",
    "    precision[key] = precision_score(predictions, Y_val, average='micro')\n",
    "    recall[key] = recall_score(predictions, Y_val, average='micro')\n",
    "    f1score[key] = f1_score(predictions, Y_val, average='micro')\n",
    "    support[key] = precision_recall_fscore_support(predictions, Y_val, average='micro')\n",
    "    Y_predict = models[key].predict(X_val)\n",
    "    auc = roc_auc_score(Y_val, Y_predict)\n",
    "    print('Classification Report: ', key)\n",
    "    print(classification_report(Y_val, predictions))\n",
    "\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_val, predictions)\n",
    "    print('ROC_AUC_SCORE is', roc_auc_score(Y_val, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=80, num=10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 17, 25, 33, 41, 48, 56, 64, 72, 80], 'max_features': ['log2', 'sqrt'], 'max_depth': [2, 4], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Create the param grid\n",
    "param_grid = { 'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 4,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_RandomGrid = RandomizedSearchCV(estimator= rf_model, param_distributions=param_grid, cv=10, verbose=2, n_jobs=4 )\n",
    "rf_RandomGrid.fit(X_train, Y_train)\n",
    "rf_RandomGrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:  Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       295\n",
      "           1       1.00      0.41      0.58        39\n",
      "\n",
      "    accuracy                           0.93       334\n",
      "   macro avg       0.96      0.71      0.77       334\n",
      "weighted avg       0.94      0.93      0.92       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models['Random Forest'] = RandomForestClassifier(n_estimators=80, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', max_depth=4, bootstrap=False)\n",
    "models['Random Forest'].fit(X_train, Y_train)\n",
    "predictions = models['Random Forest'].predict(X_val)\n",
    "\n",
    "\n",
    "accuracy['Random Forest'] = accuracy_score(predictions, Y_val)\n",
    "precision['Random Forest'] = precision_score(predictions, Y_val, average='micro')\n",
    "recall['Random Forest'] = recall_score(predictions, Y_val, average='micro')\n",
    "f1score['Random Forest'] = f1_score(predictions, Y_val, average='micro')\n",
    "support['Random Forest'] = precision_recall_fscore_support(predictions, Y_val, average='micro')\n",
    "\n",
    "print('Classification Report: ', 'Random Forest')\n",
    "print(classification_report(Y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state = 2)\n",
    "# X_train_res, y_train_res = sm.fit_resample(X_train, Y_train)\n",
    "\n",
    "# #Logistic Regression\n",
    "# lr1 = LogisticRegression(max_iter=100)\n",
    "# lr1.fit(X_train_res, y_train_res)\n",
    "# lr_predictions = lr1.predict(X_val)\n",
    "# print(classification_report(Y_val, lr_predictions))\n",
    "\n",
    "# #Random Forest\n",
    "# rf = RandomForestClassifier()\n",
    "# rf.fit(X_train_res, y_train_res)\n",
    "# rf_predictions = rf.predict(X_val)\n",
    "# print(classification_report(Y_val, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
